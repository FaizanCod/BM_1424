{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading image and converting it to grayscale\n",
    "img = cv2.imread('test_images/test_image_15.png', cv2.IMREAD_GRAYSCALE)\n",
    "  \n",
    "# # converting image into grayscale image\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# for color detection\n",
    "\n",
    "image = cv2.imread('test_images/test_image_15.png')                \n",
    "# Convert BGR to HSV\n",
    "hsv_frame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color detection:\n",
    "\n",
    "The lower and upper bounds are the boundaries of the color.\n",
    "\n",
    "low_[color]: denotes the lower threshold of the color, first argument is a np array containing RGB values, second argument denotes the datatype (unsigned int 8 bytes)\n",
    "high_[color]: denotes the higher threshold of the color\n",
    "\n",
    "\n",
    "**cv2.inRange()**\n",
    "\n",
    "inRange() function returns a binary mask of the frame where the color is present.\n",
    "\n",
    "*resultarray = inRange(sourcearray, upperboundarray, lowerboundarray)*\n",
    "\n",
    "sourcearray is the array whose elements are to be compared with the arrays representing upper bounds and lower bounds.\n",
    "\n",
    "upperboundarray is the array consisting of elements representing upper bounds.\n",
    "\n",
    "lowerboundarray is the array consisting of elements representing lower bounds.\n",
    "\n",
    "resultarray is the array representing the elements equal to either 255 or 0 returned from inRange() function.\n",
    "\n",
    "\n",
    "**cv2.dilate()**\n",
    "\n",
    "Morphological Transform: Dilation, to remove noises from the images.\n",
    "\n",
    "**cv2.bitwise_and(source1, source2, destination, mask)**\n",
    "\n",
    "bitwise_and between the image frame and mask is performed to specifically detect that particular color and discard others.\n",
    "\n",
    "source1: First Input Image array(Single-channel, 8-bit or floating-point) \n",
    "source2: Second Input Image array(Single-channel, 8-bit or floating-point) \n",
    "dest: Output array (Similar to the dimensions and type of Input image array) \n",
    "mask: Operation mask, Input / output 8-bit single-channel mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define color ranges\n",
    "\n",
    "# red color range\n",
    "low_red = np.array([0, 150, 50], np.uint8)\n",
    "high_red = np.array([10, 255, 255], np.uint8)\n",
    "red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "# red = cv2.bitwise_and(image, image, mask= red_mask)\n",
    "\n",
    "# blue color range\n",
    "low_blue = np.array([94, 80, 2], np.uint8)\n",
    "high_blue = np.array([126, 255, 255], np.uint8)\n",
    "blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "# blue = cv2.bitwise_and(image, image, mask= blue_mask)\n",
    "\n",
    "# green color range\n",
    "low_green = np.array([36, 25, 25], np.uint8)\n",
    "high_green = np.array([70, 255, 255], np.uint8)\n",
    "green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "# green = cv2.bitwise_and(image, image, mask= green_mask)\n",
    "\n",
    "# orange color range\n",
    "low_orange = np.array([15, 150, 50], np.uint8)\n",
    "high_orange = np.array([25, 255, 255], np.uint8)\n",
    "orange_mask = cv2.inRange(hsv_frame, low_orange, high_orange)\n",
    "# orange = cv2.bitwise_and(image, image, mask= orange_mask)\n",
    "\n",
    "# mask = red_mask + blue_mask + green_mask + orange_mask\n",
    "\n",
    "# color_mask = cv2.bitwise_and(image, image, mask= mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cv2.imshow(\"Color Detected\", np.hstack((image, color_mask)))\n",
    "# cv2.imshow(\"Multiple colors\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal = np.ones((6, 6), \"uint8\")\n",
    "      \n",
    "# For red color\n",
    "red_mask = cv2.dilate(red_mask, kernal)\n",
    "res_red = cv2.bitwise_and(image, image, mask = red_mask)\n",
    "      \n",
    "# For green color\n",
    "green_mask = cv2.dilate(green_mask, kernal)\n",
    "res_green = cv2.bitwise_and(image, image, mask = green_mask)\n",
    "      \n",
    "# For blue color\n",
    "blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "res_blue = cv2.bitwise_and(image, image, mask = blue_mask)\n",
    "\n",
    "# For orange color\n",
    "orange_mask = cv2.dilate(orange_mask, kernal)\n",
    "res_orange = cv2.bitwise_and(image, image, mask = orange_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to grayscale allows for easy detection of objects, but still different colours give different gradients of gray, so it is necessary to threshold them to find contours.\n",
    "\n",
    "Thresholding is a very popular segmentation technique, used for separating an object considered as a foreground from its background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.threshold**\n",
    "\n",
    "First argument is the source image, which should be a grayscale image. Second argument is the threshold value which is used to classify the pixel values. Third argument is the maxVal which represents the value to be given if pixel value is more than the threshold value. OpenCV provides different styles of thresholding and it is decided by the fourth parameter of the function.\n",
    "\n",
    "\n",
    "*cv2.THRESH_BINARY*: If pixel intensity is greater than the set threshold, value set to 255, else set to 0 (black)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.threshold(source, thresholdValue, maxVal, thresholdingTechnique)** \n",
    "\n",
    "Parameters: \n",
    "\n",
    "-> source: Input Image array (must be in Grayscale). \n",
    "\n",
    "-> thresholdValue:(all pixel values above this value will be changed to white(255), whereas other values to be changed to black(0)).\n",
    "\n",
    "-> maxVal: Maximum value that can be assigned to a pixel. \n",
    "\n",
    "-> thresholdingTechnique: The type of thresholding to be applied. \n",
    "\n",
    "cv2.threshold returns two values, only one is needed for shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshold = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity.\n",
    "\n",
    "\n",
    "There are three arguments in **cv2.findContours()** function, first one is source image, second is contour retrieval mode, third is contour approximation method. And it outputs the contours and hierarchy.\n",
    "\n",
    "\n",
    "The mode *cv2.RETR_TREE* finds all the promising contour lines and reconstructs a full hierarchy of nested contours. The method *cv2.CHAIN_APPROX_SIMPLE* returns only the endpoints that are necessary for drawing the contour line. It removes all redundant points and compresses the contour, thereby saving memory (as compared to *cv2.CHAIN_APPROX_NONE*, which stores all points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours,_ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating contour to track red color\n",
    "red_contours, _ = cv2.findContours(red_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Creating contour to track green color\n",
    "green_contours, _ = cv2.findContours(green_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  \n",
    "# Creating contour to track blue color\n",
    "blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "# Creating contour to track orange color\n",
    "orange_contours, _ = cv2.findContours(orange_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.drawContours**\n",
    "\n",
    "First argument is source and destination image, second argument is the contours which should be passed as a Python list, third argument is index of contours (useful when drawing individual contour. To draw all contours, pass -1) and remaining arguments are color, thickness etc.\n",
    "\n",
    "We'll count the vertices as the intersecting points of the contours to determine the shape.\n",
    "\n",
    "\n",
    "\n",
    "This may have errorenous contours near the vertices, so we use approximation.\n",
    "**cv2.approxPolyDP(input_curve, epsilon, closed)**\n",
    "\n",
    "It approximates a contour shape to another shape with less number of vertices depending upon the precision we specify.\n",
    "Second argument is called epsilon, which is maximum distance from contour to approximated contour. It is an accuracy parameter. A wise selection of epsilon is needed to get the correct output. The third argument is True, which indicates that the shape is closed.\n",
    "\n",
    "\n",
    "**cv2.arcLength()** is used to calculate the perimeter of the contour(cnt) and takes 1% (0.01) of this length for cv2.approxPolyDP as epsilon. If the second argument is True then it considers the contour to be closed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 509\n",
      "601 506\n",
      "317 320\n",
      "602 234\n",
      "201 218\n",
      "292 161\n",
      "395 165\n",
      "203 98\n",
      "793 96\n"
     ]
    }
   ],
   "source": [
    "#to loop over the contours\n",
    "i=0\n",
    "for cnt in contours:\n",
    "    \n",
    "    # here we are ignoring first counter because \n",
    "    # findcontour function detects whole image as shape\n",
    "    if i==0:\n",
    "        i=1\n",
    "        continue\n",
    "        \n",
    "    # using drawContours() function (non-approximated)\n",
    "    #cv2.drawContours(img, [contour], 0, (0, 0, 255), 5)\n",
    "    \n",
    "    #approximating\n",
    "    approx = cv2.approxPolyDP(cnt, 0.025*cv2.arcLength(cnt, True), True)\n",
    "    \n",
    "    #img changed to image\n",
    "    cv2.drawContours(image, [approx], 0, (0), 3)\n",
    "    \n",
    "    # printing the values in approx\n",
    "    # print(len(approx))\n",
    "    \n",
    "    # finding out the top coordinates of each shape\n",
    "    x = approx.ravel()[0]\n",
    "    y = approx.ravel()[1]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    # putting shape name at top of each shape\n",
    "    if len(approx) == 3:\n",
    "        #img changed to image\n",
    "        cv2.putText(image, 'Triangle', (x, y), font, 1.0, (0, 0, 0))\n",
    "  \n",
    "    elif len(approx) == 4:\n",
    "        \n",
    "        # for distinguishing between rectangle and square\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "\n",
    "        aspectRatio = float (w)/h\n",
    "        if aspectRatio >= 0.95 and aspectRatio <= 1.05:\n",
    "            #img changed to image\n",
    "            cv2.putText(image, 'Square', (x, y), font, 1.0, (0, 0, 0))\n",
    "        else:\n",
    "            cv2.putText(image, 'Rectangle', (x, y), font, 1.0, (0, 0, 0))\n",
    "    \n",
    "    elif len(approx) == 5:\n",
    "        #img changed to image\n",
    "        cv2.putText(image, 'Pentagon', (x, y), font, 1.0, (0, 0, 0))\n",
    "  \n",
    "    else:\n",
    "        #img changed to image\n",
    "        cv2.putText(image, 'Circle', (x, y), font, 1.0, (0, 0, 0))\n",
    "        \n",
    "    # finding center point of shape\n",
    "    M = cv2.moments(cnt)\n",
    "    if M['m00'] != 0.0:\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "    print(cx,cy)\n",
    "    \n",
    "    image = cv2.circle(image, (cx,cy), radius=2, color=(0, 0, 0), thickness=-1)\n",
    "    \n",
    "    #COLOR\n",
    "    #RED\n",
    "    for pic, contour in enumerate(red_contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "#         image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 0), 2)\n",
    "              \n",
    "        cv2.putText(image, \"Red\", (x-50, y+h+8), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0))   \n",
    "    \n",
    "    #GREEN\n",
    "    for pic, contour in enumerate(green_contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "#         image = cv2.rectangle(image, (x, y),  (x + w, y + h), (0, 0, 0), 2)\n",
    "              \n",
    "        cv2.putText(image, \"Green\", (x-50, y+h+8), cv2.FONT_HERSHEY_SIMPLEX,  1.0, (0, 0, 0))\n",
    "        \n",
    "    #BLUE\n",
    "    for pic, contour in enumerate(blue_contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "#         image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 0), 2)\n",
    "              \n",
    "        cv2.putText(image, \"Blue\", (x-50, y+h+8), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0))\n",
    "        \n",
    "    #ORANGE\n",
    "    for pic, contour in enumerate(orange_contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "#         image = cv2.rectangle(image, (x, y),  (x + w, y + h), (0, 0, 0), 2)\n",
    "              \n",
    "        cv2.putText(image, \"Orange\", (x-50, y+h+8), cv2.FONT_HERSHEY_SIMPLEX,  1.0, (0, 0, 0))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**approx.ravel()**\n",
    "\n",
    "If we just print approx it'll print an array of array of the coordinates of the polygon, ravel() function shortens it to a single array. For each iteration of the for loop the first coordinates (x and y) are given by approx.ravel()[0] and approx.ravel()[1].\n",
    "\n",
    "\n",
    "\n",
    "**cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])**\n",
    "\n",
    "image: It is the image on which text is to be drawn.\n",
    "\n",
    "text: Text string to be drawn.\n",
    "\n",
    "org: It is the coordinates of the bottom-left corner of the text string in the image. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "\n",
    "font: It denotes the font type. Some of font types are FONT_HERSHEY_SIMPLEX, FONT_HERSHEY_PLAIN, , etc.\n",
    "\n",
    "fontScale: Font scale factor that is multiplied by the font-specific base size.\n",
    "\n",
    "color: It is the color of text string to be drawn. For BGR, we pass a tuple. eg: (0, 0, 0) for black color.\n",
    "\n",
    "thickness: It is the thickness of the line in px.\n",
    "\n",
    "lineType: This is an optional parameter.It gives the type of the line to be used.\n",
    "\n",
    "bottomLeftOrigin: This is an optional parameter. When it is true, the image data origin is at the bottom-left corner. Otherwise, it is at the top-left corner.\n",
    "\n",
    "\n",
    "\n",
    "**cv2.boundingRect()**\n",
    "\n",
    "It is a function used to create an approximate rectangle along with the image. This function’s primary use is to highlight the area of interest after obtaining the image’s outer shape. With proper markings, the users can easily highlight the desired aspect in an image.\n",
    "\n",
    "Let (x,y) be the top-left coordinate of the rectangle and (w,h) be its width and height.\n",
    "aspectRatio is the ratio of width (w) by height (h). Ideally, for a square, its aspect ratio is 1, but we do incorporate some noises that may have crept in by taking it between 0.95 and 1.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Moment is a particular weighted average of image pixel intensities, with the help of which we can find some specific properties of an image, like radius, area, centroid etc. To find the centroid of the image, we generally convert it to binary format and then find its center.\n",
    "\n",
    "**cv2.moments()**\n",
    "\n",
    "cv2.threshold returns two values, only one is needed for shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"shapes\", image)\n",
    "# cv2.imshow(\"Thresholded\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Multiple colors\", image)\n",
    "# cv2.imshow(\"Shapes\", img)\n",
    "cv2.imshow(\"Colors+Shapes\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "389ac146d8a07d7e99ae9dedf984517cf329a542bee82cad8836b84c093c56c0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
