{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To highlight the issue in test_image_14.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(contour):\n",
    "\n",
    "    centroid = []\n",
    "\n",
    "    M = cv2.moments(contour)\n",
    "    if M['m00'] != 0.0:\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "\n",
    "        centroid.append((cx,cy))\n",
    "\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors_detected(img):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    This function takes the image as argument and returns a dictionary\n",
    "    denoting the color of the shapes in the image.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    `img` : [ numpy array ]\n",
    "            numpy array of image returned by cv2 library\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `detected_colors` : {dictionary}\n",
    "            dictionary containing details of colors present in image\n",
    "    \"\"\"\n",
    "    detected_colors = {}\n",
    "    \n",
    "    image = cv2.imread(img)                \n",
    "    # Convert BGR to HSV\n",
    "    hsv_frame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # defining color ranges\n",
    "\n",
    "    # red color range\n",
    "    low_red = np.array([0, 150, 50], np.uint8)\n",
    "    high_red = np.array([10, 255, 255], np.uint8)\n",
    "    red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "\n",
    "    # blue color range\n",
    "    low_blue = np.array([94, 80, 2], np.uint8)\n",
    "    high_blue = np.array([126, 255, 255], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "\n",
    "    # green color range\n",
    "    low_green = np.array([36, 25, 25], np.uint8)\n",
    "    high_green = np.array([70, 255, 255], np.uint8)\n",
    "    green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "\n",
    "    # orange color range\n",
    "    low_orange = np.array([15, 150, 50], np.uint8)\n",
    "    high_orange = np.array([25, 255, 255], np.uint8)\n",
    "    orange_mask = cv2.inRange(hsv_frame, low_orange, high_orange)\n",
    "\n",
    "    #Morphological Transform: Dilation, to remove noises from the images and performing bitwise_and function to specifically detect a particular color.\n",
    "\n",
    "    kernal = np.ones((6, 6), \"uint8\")\n",
    "      \n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernal)\n",
    "    res_red = cv2.bitwise_and(image, image, mask = red_mask)\n",
    "      \n",
    "    # For green color\n",
    "    green_mask = cv2.dilate(green_mask, kernal)\n",
    "    res_green = cv2.bitwise_and(image, image, mask = green_mask)\n",
    "      \n",
    "    # For blue color\n",
    "    blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "    res_blue = cv2.bitwise_and(image, image, mask = blue_mask)\n",
    "\n",
    "    # For orange color\n",
    "    orange_mask = cv2.dilate(orange_mask, kernal)\n",
    "    res_orange = cv2.bitwise_and(image, image, mask = orange_mask)\n",
    "\n",
    "    # Contours for color detection\n",
    "\n",
    "    # Creating contour to track red color\n",
    "    red_contours, _ = cv2.findContours(red_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Creating contour to track green color\n",
    "    green_contours, _ = cv2.findContours(green_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  \n",
    "    # Creating contour to track blue color\n",
    "    blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    # Creating contour to track orange color\n",
    "    orange_contours, _ = cv2.findContours(orange_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # taking a counter variable to allow for detection of each shape\n",
    "#     count = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # RED\n",
    "    for contour in red_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "#             centroid_all(img)\n",
    "#             print(centroid)\n",
    "            centroids = centroid(contour)\n",
    "            # accessing the centroid cx, cy values\n",
    "#             c = centroids[count]\n",
    "            cx = centroids[0][0]\n",
    "            cy = centroids[0][1]\n",
    "            \n",
    "            detected_colors[cx,cy] = ['Red']\n",
    "    \n",
    "    #BLUE\n",
    "    for contour in blue_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "#             centroid_all(img)\n",
    "#             print(centroid)\n",
    "            centroids = centroid(contour)\n",
    "            # accessing the centroid cx, cy values\n",
    "#             c = centroids[count]\n",
    "            cx = centroids[0][0]\n",
    "            cy = centroids[0][1]\n",
    "\n",
    "            detected_colors[cx,cy] = ['Blue']\n",
    "            \n",
    "    #GREEN\n",
    "    for contour in green_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if(area > 300):\n",
    "#             centroid_all(img)\n",
    "#             print(centroid)\n",
    "            centroids = centroid(contour)\n",
    "            # accessing the centroid cx, cy values\n",
    "#             c = centroids[count]\n",
    "            cx = centroids[0][0]\n",
    "            cy = centroids[0][1]\n",
    "\n",
    "            detected_colors[cx,cy] = ['Green']\n",
    "        \n",
    "    #ORANGE\n",
    "    for contour in orange_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "#         rect = cv2.boundingRect(contour)\n",
    "#         area = rect[2] * rect[3]\n",
    "#         print(area)\n",
    "        #approximating\n",
    "        approx = cv2.approxPolyDP(contour, 0.025*cv2.arcLength(contour, True), True)\n",
    "    \n",
    "        #img changed to image\n",
    "        cv2.drawContours(image, [approx], 0, (0), 3) \n",
    "        if(area > 300):\n",
    "            \n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 0), 2)\n",
    "            cv2.putText(image, \"Orange\", (x-50, y+h+8), cv2.FONT_HERSHEY_SIMPLEX,  1.0, (0, 0, 0))\n",
    "            \n",
    "\n",
    "            \n",
    "            cv2.imshow(\"Colors+Shapes\",image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "#             cv2.drawContours(image, [contour], -1, (0, 0, 255), 5)\n",
    "    \n",
    "#             centroid_all(img)\n",
    "#             print(centroid)\n",
    "            centroids = centroid(contour)\n",
    "            # accessing the centroid cx, cy values\n",
    "#             c = centroids[count]\n",
    "            cx = centroids[0][0]\n",
    "            cy = centroids[0][1]\n",
    "        \n",
    "            detected_colors[cx,cy] = ['Orange']\n",
    "\n",
    "    return detected_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(589, 370): ['Red'], (326, 146): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_1.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(302, 119): ['Red'], (275, 349): ['Blue'], (649, 420): ['Blue'], (766, 165): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_2.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(644, 194): ['Red'], (426, 273): ['Blue'], (468, 467): ['Green'], (290, 110): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_3.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(249, 199): ['Red'], (326, 452): ['Blue'], (589, 227): ['Blue']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_4.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(648, 398): ['Red'], (631, 150): ['Blue'], (184, 106): ['Blue'], (308, 370): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_5.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(302, 119): ['Red'], (275, 349): ['Blue'], (649, 420): ['Blue'], (766, 165): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_6.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(648, 199): ['Red'], (308, 227): ['Red'], (184, 492): ['Blue'], (546, 457): ['Blue'], (104, 108): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_7.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(517, 352): ['Red'], (160, 235): ['Red'], (295, 503): ['Blue'], (102, 87): ['Blue'], (660, 117): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_8.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(295, 503): ['Blue'], (517, 352): ['Blue'], (102, 87): ['Blue'], (198, 247): ['Green'], (660, 117): ['Green']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_9.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(789, 477): ['Red'], (421, 454): ['Red'], (108, 341): ['Red'], (185, 212): ['Blue'], (92, 89): ['Blue']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_10.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(290, 110): ['Red'], (644, 194): ['Red'], (468, 467): ['Blue'], (426, 273): ['Blue']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_11.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(789, 477): ['Red'], (421, 454): ['Red'], (108, 341): ['Red'], (185, 212): ['Blue'], (92, 89): ['Blue']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_12.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(530, 326): ['Red'], (122, 220): ['Red'], (651, 402): ['Blue'], (647, 199): ['Blue'], (778, 482): ['Green'], (453, 504): ['Orange']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_13.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(215, 247): ['Red'], (162, 184): ['Red'], (101, 102): ['Red'], (254, 340): ['Blue'], (308, 248): ['Orange'], (450, 103): ['Orange']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_14.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(202, 218): ['Red'], (396, 165): ['Red'], (204, 98): ['Red'], (83, 510): ['Blue'], (318, 321): ['Blue'], (292, 161): ['Blue'], (794, 97): ['Blue'], (602, 505): ['Orange'], (602, 236): ['Orange']}\n"
     ]
    }
   ],
   "source": [
    "print(colors_detected('test_images/test_image_15.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BM_1424",
   "language": "python",
   "name": "bm_1424"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
